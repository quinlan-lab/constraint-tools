#!/usr/bin/env python

# pysam API: 
# https://github.com/pysam-developers/pysam/blob/b82cbcae22c088e64fdb58f8acaf1e9773c7b088/pysam/libctabix.pyx
import pysam

import numpy as np
import json
import argparse 
import os
import subprocess
import multiprocessing

from kmer import (
  initialize_kmer_counts_germline, 
  fetch_kmer_from_sequence, 
  contains_unspecified_bases,
  middle_base
)
from colorize import (
  print_json, 
  print_string_as_info, 
  print_string_as_info_dim, 
  print_unbuffered
)
import color_traceback 
from snvs import fetch_SNVs, reduce_SNVs
from pack_unpack import unpack
from timer import timer 
from windows import create_windows 

# using the "khmer" library might make this function a handful of times faster:
# https://khmer.readthedocs.io/en/v0.6.1-0/ktable.html
def compute_kmer_total_counts(genome, kmer_counts, args): 
  # "fetch" API: https://pysam.readthedocs.io/en/latest/api.html?highlight=fasta#pysam.FastaFile
  # Note that fetch(region=region) does not work if the coordinates in "region" contains commas
  # Workaround is to parse "region" into "chromosome", "start", "end": 
  neutral_sequence = genome.fetch(*unpack(args.neutral_region))    
  print_string_as_info(f"Sequence for neutral region coordinates {args.neutral_region} is:")
  print_string_as_info_dim(f"{neutral_sequence}")
  print_unbuffered('')

  # TODO: refactor this to use the "windows" module 
  print_string_as_info('Iterating over neutral region {} and counting kmers:'.format(args.neutral_region))
  start_position = 0 + args.kmer_size//2
  end_position = len(neutral_sequence) - args.kmer_size//2 
  number_of_sites_containing_unspecified_bases = 0
  for position in np.arange(start_position, end_position, 1): 
    kmer = fetch_kmer_from_sequence(neutral_sequence, position, args.kmer_size)
    if contains_unspecified_bases(middle_base(kmer)): 
      number_of_sites_containing_unspecified_bases += 1
    if contains_unspecified_bases(kmer): continue 
    kmer_counts[kmer]['count'] += 1

  number_of_sites = end_position - start_position
  print_string_as_info_dim(
    f'Number of sites in {args.neutral_region} containing unspecified bases: '
    f'{number_of_sites_containing_unspecified_bases}/{number_of_sites}'
  )
  print_unbuffered('')

  return kmer_counts

def compute_kmer_SNV_counts(mutations, genome, kmer_counts, args):
  print_string_as_info('Fetching SNVs in region {} and incrementing corresponding kmer counts\n'.format(args.neutral_region))

  SNVs = fetch_SNVs(mutations, genome, args.neutral_region, args.__dict__)
  SNVs = reduce_SNVs(SNVs)
  for SNV in SNVs: 
    kmer_counts[SNV['kmer']]['ALTStateCounts'][SNV['ALTState']] += 1
  return kmer_counts

def get_hostname_process_cpu(): 
  hostname = os.uname()[1]
  pid = os.getpid()
  cpu = subprocess.run(
    ["ps", "-o", "psr=", "-p", f"{pid}"], 
    capture_output=True
  ).stdout.decode("utf-8").strip()
  return {
    'hostname': hostname,
    'process': pid, 
    'cpu': f'{cpu}/{multiprocessing.cpu_count()}'
  }

def parse_arguments():
  parser = argparse.ArgumentParser(description='')
  parser.add_argument('--kmer-size', type=int, dest='kmer_size', help='')
  parser.add_argument('--genome', type=str, help='')
  parser.add_argument('--number-chromosomes-min', type=int, dest='number_chromosomes_min', help='')
  parser.add_argument('--mutations', type=str, help='')
  parser.add_argument('--window-size', type=int, dest='window_size', help='')
  parser.add_argument('--neutral-regions-filename', type=str, dest='neutral_regions_filename', help='')
  parser.add_argument('--counts-filename', type=str, dest='counts_filename', help='')
  return parser.parse_args()

def compute_SNV_and_singleton_counts(mutations, genome, args): 
  print_string_as_info('Breaking neutral region into non-overlapping windows, and counting SNVs and singletons per window...')

  windows = create_windows(
    window_size=args.window_size, 
    window_stride=args.window_size, 
    region=args.neutral_region, 
    genome=genome, 
    region_contains_windows=True
  )
  print_string_as_info_dim(f'Created {len(windows)} windows within neutral region {args.neutral_region}')

  SNV_and_singleton_counts = []
  for window in windows: 
    SNVs = fetch_SNVs(mutations, genome, window['region'], args.__dict__, args.number_chromosomes_min)
    SNV_count = len(SNVs)
    singleton_count = len([SNV for SNV in SNVs if SNV['number_ALT_chromosomes'] == 1])
    print_string_as_info_dim(f"{singleton_count} of {SNV_count} SNVs in {window['region']} are singletons")
    SNV_and_singleton_counts.append((SNV_count, singleton_count))

  print_unbuffered('')

  return SNV_and_singleton_counts

@timer
def count_on_region(neutral_region):
  print_json({'neutral regions': args.neutral_regions_filename, **get_hostname_process_cpu()})
  kmer_counts = initialize_kmer_counts_germline(args) 

  # pysam.FastaFile uses the index produced by "samtools faidx": 
  # https://pysam.readthedocs.io/en/latest/api.html?highlight=fasta#pysam.FastaFile
  with pysam.TabixFile(args.mutations) as mutations, pysam.FastaFile(args.genome) as genome: 
    kmer_counts = compute_kmer_total_counts(genome, kmer_counts, args) 
    kmer_counts = compute_kmer_SNV_counts(mutations, genome, kmer_counts, args)
    SNV_and_singleton_counts = compute_SNV_and_singleton_counts(mutations, genome, args)

  return kmer_counts, SNV_and_singleton_counts

# https://realpython.com/introduction-to-python-generators/
def fetch_counts(count_type, neutral_regions, progress_bar): 
  # TODO: is this common to estimate-probabilities ??
  for neutral_region in tqdm(neutral_regions, file=progress_bar, desc=count_type): 
    kmer_counts, SNV_and_singleton_counts = count_on_region(neutral_region)
    yield { 
      'kmerCounts': kmer_counts,
      'snvAndSingletonCounts': SNV_and_singleton_counts
    }

def aggregate_counts_over_neutral_regions_core(): 
  # TODO: factor out kmer_counts and conditional_singleton_counts logic from here and estimate-probabilities

  print_string_as_info('Combining kmer counts across neutral regions...')
  kmer_counts = functools.reduce(combine_kmer_counts, fetch_counts(args, kmerCounts_log)['kmerCounts'])

  print_string_as_info('Combining snv and singleton counts across neutral regions...')
  conditional_singleton_counts = Conditional_Singleton_Counts()
  number_neutral_windows = 0
  for SNV_and_singleton_counts in fetch_counts(args, snvAndSingletonCounts_log)['snvAndSingletonCounts']:
    number_neutral_windows += len(SNV_and_singleton_counts)
    for SNV_and_singleton_count in SNV_and_singleton_counts: 
      SNV_count, singleton_count = map(int, SNV_and_singleton_count)
      assert singleton_count >= 0 
      assert singleton_count <= SNV_count 
      conditional_singleton_counts[SNV_count][singleton_count] += 1 

  with open(args.counts_filename, 'w') as fh:
    json.dump({
      'mutations': args.mutations,
      'genome': args.genome,
      'kmerSize': args.kmer_size,
      'numberChromosomesMin': args.number_chromosomes_min,
      'windowSize': args.window_size,
      'kmerCounts': kmer_counts,
      'snvAndSingletonCounts': SNV_and_singleton_counts
    }, fh, indent=2)

def aggregate_counts_over_neutral_regions(): 
  args = parse_arguments()  

  # TODO: factor out this logic, which is common to estimate-probabilities 

  # tqdm log: 
  # https://github.com/tqdm/tqdm/issues/506#issuecomment-373762049
  # https://github.com/tqdm/tqdm/issues/506#issuecomment-508458426
  if args.progress_bar == 'stdout': 
    aggregate_counts_over_neutral_regions_core(args, kmerCounts_log=sys.stdout, snvAndSingletonCounts_log=sys.stdout)
  else: 
    with (
      open(f'{args.progress_bar}/kmerCounts.log', 'w') as kmerCounts_log, 
      open(f'{args.progress_bar}/snvAndSingletonCounts.log', 'w') as snvAndSingletonCounts_log
    ):
      aggregate_counts_over_neutral_regions_core(args, kmerCounts_log, snvAndSingletonCounts_log)

if __name__ == '__main__':
  aggregate_counts_over_neutral_regions()  

