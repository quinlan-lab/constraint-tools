{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTRAINT_TOOLS = '/scratch/ucgd/lustre-work/quinlan/u6018199/constraint-tools'\n",
    "CONSTRAINT_TOOLS_DATA = '/scratch/ucgd/lustre-work/quinlan/data-shared/constraint-tools'\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'{CONSTRAINT_TOOLS}/utilities')\n",
    "\n",
    "LARGE_WINDOW_SIZE = 10000\n",
    "LARGE_WINDOW_FILENAME = f'{CONSTRAINT_TOOLS_DATA}/benchmark-genome-wide-predictions/chen-et-al-2022/large-windows.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make large windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from shell import shell \n",
    "\n",
    "def make_large_windows(): \n",
    "  chromosome_sizes = f'{CONSTRAINT_TOOLS_DATA}/reference/grch38/chromosome-sizes/hg38.chrom.sizes.sorted'\n",
    "  cmd = f'bedtools makewindows -g {chromosome_sizes} -w {LARGE_WINDOW_SIZE} > {LARGE_WINDOW_FILENAME}'    \n",
    "  shell(cmd)\n",
    "\n",
    "make_large_windows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute characteristics of overlapping deletions per large window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36mWrote (filtered) large windows with intersecting topmed deletions to: \u001b[0m/scratch/ucgd/lustre-work/quinlan/data-shared/constraint-tools/benchmark-genome-wide-predictions/chen-et-al-2022/filtered-large-windows-with-deletions.bed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom_window</th>\n",
       "      <th>start_window</th>\n",
       "      <th>end_window</th>\n",
       "      <th>number_of_overlapping_topmed_deletions</th>\n",
       "      <th>chrom_merged_deletion</th>\n",
       "      <th>start_merged_deletion</th>\n",
       "      <th>end_merged_deletion</th>\n",
       "      <th>window_merged_deletion_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2300000</td>\n",
       "      <td>2310000</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2310000</td>\n",
       "      <td>2320000</td>\n",
       "      <td>5</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2311495</td>\n",
       "      <td>2335000</td>\n",
       "      <td>8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2320000</td>\n",
       "      <td>2330000</td>\n",
       "      <td>4</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2311495</td>\n",
       "      <td>2335000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2330000</td>\n",
       "      <td>2340000</td>\n",
       "      <td>2</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2311495</td>\n",
       "      <td>2335000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2340000</td>\n",
       "      <td>2350000</td>\n",
       "      <td>3</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2340700</td>\n",
       "      <td>2356411</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262886</th>\n",
       "      <td>chr22</td>\n",
       "      <td>49050000</td>\n",
       "      <td>49060000</td>\n",
       "      <td>5</td>\n",
       "      <td>chr22</td>\n",
       "      <td>39415437</td>\n",
       "      <td>49170200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262887</th>\n",
       "      <td>chr22</td>\n",
       "      <td>49060000</td>\n",
       "      <td>49070000</td>\n",
       "      <td>7</td>\n",
       "      <td>chr22</td>\n",
       "      <td>39415437</td>\n",
       "      <td>49170200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262888</th>\n",
       "      <td>chr22</td>\n",
       "      <td>49070000</td>\n",
       "      <td>49080000</td>\n",
       "      <td>4</td>\n",
       "      <td>chr22</td>\n",
       "      <td>39415437</td>\n",
       "      <td>49170200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262889</th>\n",
       "      <td>chr22</td>\n",
       "      <td>49080000</td>\n",
       "      <td>49090000</td>\n",
       "      <td>2</td>\n",
       "      <td>chr22</td>\n",
       "      <td>39415437</td>\n",
       "      <td>49170200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262890</th>\n",
       "      <td>chr22</td>\n",
       "      <td>49090000</td>\n",
       "      <td>49100000</td>\n",
       "      <td>3</td>\n",
       "      <td>chr22</td>\n",
       "      <td>39415437</td>\n",
       "      <td>49170200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262891 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrom_window  start_window  end_window  \\\n",
       "0              chr1       2300000     2310000   \n",
       "1              chr1       2310000     2320000   \n",
       "2              chr1       2320000     2330000   \n",
       "3              chr1       2330000     2340000   \n",
       "4              chr1       2340000     2350000   \n",
       "...             ...           ...         ...   \n",
       "262886        chr22      49050000    49060000   \n",
       "262887        chr22      49060000    49070000   \n",
       "262888        chr22      49070000    49080000   \n",
       "262889        chr22      49080000    49090000   \n",
       "262890        chr22      49090000    49100000   \n",
       "\n",
       "        number_of_overlapping_topmed_deletions chrom_merged_deletion  \\\n",
       "0                                            0                     .   \n",
       "1                                            5                  chr1   \n",
       "2                                            4                  chr1   \n",
       "3                                            2                  chr1   \n",
       "4                                            3                  chr1   \n",
       "...                                        ...                   ...   \n",
       "262886                                       5                 chr22   \n",
       "262887                                       7                 chr22   \n",
       "262888                                       4                 chr22   \n",
       "262889                                       2                 chr22   \n",
       "262890                                       3                 chr22   \n",
       "\n",
       "        start_merged_deletion  end_merged_deletion  \\\n",
       "0                          -1                   -1   \n",
       "1                     2311495              2335000   \n",
       "2                     2311495              2335000   \n",
       "3                     2311495              2335000   \n",
       "4                     2340700              2356411   \n",
       "...                       ...                  ...   \n",
       "262886               39415437             49170200   \n",
       "262887               39415437             49170200   \n",
       "262888               39415437             49170200   \n",
       "262889               39415437             49170200   \n",
       "262890               39415437             49170200   \n",
       "\n",
       "        window_merged_deletion_overlap  \n",
       "0                                    0  \n",
       "1                                 8505  \n",
       "2                                10000  \n",
       "3                                 5000  \n",
       "4                                 9300  \n",
       "...                                ...  \n",
       "262886                           10000  \n",
       "262887                           10000  \n",
       "262888                           10000  \n",
       "262889                           10000  \n",
       "262890                           10000  \n",
       "\n",
       "[262891 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# intersect large windows with deletions (both het and homalt), and filter out suspect large windows\n",
    "def read_large_windows_intersect_all_deletions():\n",
    "  cmd = f'bash {CONSTRAINT_TOOLS}/experiments/germline-model/chen-et-al-2022/intersect-large-windows-with-topmed-deletions-and-filter.sh'\n",
    "  print(shell(cmd))\n",
    "  df = pd.read_csv(\n",
    "    f\"{CONSTRAINT_TOOLS_DATA}/benchmark-genome-wide-predictions/chen-et-al-2022/filtered-large-windows-with-deletions.bed\", \n",
    "    sep = '\\t',\n",
    "  )  \n",
    "  df = df[\n",
    "    (df['chrom_window'] != 'chrX') &\n",
    "    (df['chrom_window'] != 'chrY')\n",
    "  ]\n",
    "  return df \n",
    "  \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "LARGE_WINDOWS_WITH_DELETIONS = read_large_windows_intersect_all_deletions()\n",
    "LARGE_WINDOWS_WITH_DELETIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get small windows with constraint labels, and Chen variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "def compute_N_mean_null_chen(row): \n",
    "    a = 1 \n",
    "    b = -(2*row['N_observed'] + row['new chen zscore']**2)\n",
    "    c = row['N_observed']**2\n",
    "    sqrt = np.sqrt(b**2 - 4*a*c)\n",
    "    sign = 1 if row['new chen zscore'] > 0 else -1\n",
    "    return (-b + sign*sqrt)/(2*a)\n",
    "    \n",
    "\n",
    "def get_noncoding_nonenhancer_windows():\n",
    "  # this bed file has already been aggregated to the window level: \n",
    "  # experiments/germline-model/chen-et-al-2022/enhancer-characteristics-enrichment.ipynb \n",
    "  filename = f'{CONSTRAINT_TOOLS_DATA}/benchmark-genome-wide-predictions/chen-et-al-2022/enhancer-characteristics-enrichment.bed'\n",
    "  df = pd.read_csv(filename, sep='\\t')\n",
    "  return df \n",
    "\n",
    "  # TODO \n",
    "  df['N_mean_null_chen'] = df.apply(compute_N_mean_null_chen, axis=1)\n",
    "\n",
    "  df = df[df['window overlaps merged_exon'] == False] # noncoding\n",
    "  df = df[df['window overlaps enhancer'] == False] # nonenhancer\n",
    "\n",
    "  df = df.drop_duplicates() \n",
    "  df = df[[\n",
    "    'chromosome', 'start', 'end',\n",
    "    'negative new chen zscore'\n",
    "  ]]\n",
    "  df = df.rename(columns={\n",
    "    'chromosome': 'chrom', \n",
    "    'negative new chen zscore': 'min negative_new_chen_score_window'\n",
    "  }) # type: ignore\n",
    "  df = df.sample(NUMBER_NEGATIVE_EXAMPLES, random_state=42) # assume most such windows are nonconstrained\n",
    "  df['truly constrained'] = False\n",
    "  df['tag'] = 'random_noncoding_nonenhancer'\n",
    "  df['count negative_new_chen_score_window'] = 1\n",
    "  return df\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "get_noncoding_nonenhancer_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_regions_non_overlapping():\n",
    "  count_self_intersections = (\n",
    "    f'bedtools intersect'\n",
    "    f\" -a <(tail -n +2 {CONSTRAINT_TOOLS_DATA}/khurana/{LABELED_REGIONS})\"\n",
    "    f\" -b <(tail -n +2 {CONSTRAINT_TOOLS_DATA}/khurana/{LABELED_REGIONS})\"\n",
    "    f' -wao'\n",
    "    f' | wc -l'\n",
    "  )\n",
    "  number_self_intersections = shell(count_self_intersections)\n",
    "  count_number_lines = f'tail -n +2 {CONSTRAINT_TOOLS_DATA}/khurana/{LABELED_REGIONS} | wc -l'\n",
    "  number_lines = shell(count_number_lines)\n",
    "  if number_self_intersections != number_lines:\n",
    "    raise Exception(f'number of self-intersections ({number_self_intersections}) != number of lines ({number_lines})')\n",
    "  else: \n",
    "    print(f'regions ({number_self_intersections}) are non-overlapping')\n",
    "\n",
    "def create_and_save_labeled_regions(): \n",
    "  positive_examples = pd.concat([    \n",
    "    aggregate_over_windows(read_disease_enhancers_intersect_chen_windows()),\n",
    "    aggregate_over_windows(read_low_lof_tolerance_enhancers_intersect_chen_windows())\n",
    "  ])\n",
    "\n",
    "  negative_examples = get_noncoding_nonenhancer_windows()\n",
    "\n",
    "  df = pd.concat([positive_examples, negative_examples])\n",
    "\n",
    "  df = df.reset_index(drop=True) # create new index and drop old index\n",
    "  df = df.reset_index(drop=False) # make new index into a column\n",
    "  df = df.rename(columns={'index': 'region_id'})\n",
    "  new_order = df.columns[1:].tolist() + ['region_id']\n",
    "  df = df.reindex(columns=new_order)\n",
    "  \n",
    "  print('number of regions that are truly constrained (True) or not (False):') \n",
    "  print(df['truly constrained'].value_counts())\n",
    "\n",
    "  df.to_csv(f\"{CONSTRAINT_TOOLS_DATA}/khurana/{LABELED_REGIONS}\", sep='\\t', index=False)\n",
    "\n",
    "  check_regions_non_overlapping() \n",
    "\n",
    "  return df \n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "create_and_save_labeled_regions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect labeled regions with ALL deletions from TopMed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def collapse(ser): \n",
    "  unique_value, = set(ser)\n",
    "  return unique_value\n",
    "\n",
    "def count(ser): \n",
    "  if len(ser) == 1 and ser.iloc[0] == '.': return 0\n",
    "  return len(ser) \n",
    "\n",
    "def custom_max(ser): \n",
    "  if len(ser) == 1 and ser.iloc[0] == '.': return '.'\n",
    "  return np.max([int(value) for value in list(ser)])\n",
    "\n",
    "def custom_list(ser): \n",
    "  if len(ser) == 1 and ser.iloc[0] == '.': return '.'\n",
    "  return list(ser)\n",
    "\n",
    "def aggregate_over_deletions(df, group_columns, aggregation_functions): \n",
    "  groups = df.groupby(group_columns)\n",
    "  aggregated = groups.agg(aggregation_functions)  \n",
    "  df = aggregated.reset_index()\n",
    "  df.columns = [' '.join(col[::-1]).strip() for col in df.columns.values]\n",
    "  return df\n",
    "\n",
    "def read_labeled_regions_intersect_all_deletions():\n",
    "  cmd = f'bash {CONSTRAINT_TOOLS}/experiments/germline-model/chen-et-al-2022/intersect-labeled-regions-{VERSION}-with-topmed-deletions.sh {VERSION}'\n",
    "  print(shell(cmd))\n",
    "  df = pd.read_csv(\n",
    "    f\"{CONSTRAINT_TOOLS_DATA}/khurana/labeled-regions-{VERSION}-intersect-topmed-deletions.bed\", \n",
    "    sep = '\\t',\n",
    "  )  \n",
    "  group_columns = [\n",
    "    'chrom',\n",
    "    'start',\n",
    "    'end',\n",
    "    'truly constrained',\n",
    "    'tag',\n",
    "    'min negative_new_chen_score_window',\n",
    "    'count negative_new_chen_score_window',\n",
    "    'region_id'\n",
    "  ]\n",
    "  aggregation_functions = {\n",
    "    'SVLEN': [custom_max],\n",
    "    'SVTYPE': [collapse, count],\n",
    "    # 'SV_ID': [custom_list],\n",
    "    'Het': [custom_max],\n",
    "    'HomAlt': [custom_max],\n",
    "    # 'region-deletion-overlap': [custom_max]\n",
    "  }\n",
    "  aggregation_columns = list(aggregation_functions.keys())\n",
    "  new_columns = group_columns + aggregation_columns\n",
    "  df = df[new_columns]\n",
    "  df = aggregate_over_deletions(df, group_columns, aggregation_functions)\n",
    "  df = df.rename(columns={\n",
    "    'chrom': 'chrom_region',\n",
    "    'start': 'start_region',\n",
    "    'end': 'end_region',\n",
    "  })\n",
    "  df['region is deleted in topmed'] = df['collapse SVTYPE'] == 'DEL'\n",
    "  print('number of regions that are deleted in TopMed (True) or not (False):')\n",
    "  print(df['region is deleted in topmed'].value_counts())\n",
    "  return df   \n",
    "  \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "REGIONS = read_labeled_regions_intersect_all_deletions()\n",
    "REGIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chen zscore to predict whether a region is critical or not, and improving that prediction using TopMed deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set the font size\n",
    "mpl.rcParams['font.size'] = 20\n",
    "\n",
    "def plot_score_distributions(df, score, xlabel, bins, xlim=None):\n",
    "  ax = sns.histplot(data=df, x=score, kde=True, bins=bins, hue='truly constrained', stat='count') # stat='density'\n",
    "  ax.set_xlabel(xlabel)\n",
    "  ax.set_ylabel('Number of regions')\n",
    "  if xlim is not None: ax.set_xlim(xlim)\n",
    "  legend = ax.get_legend()\n",
    "  legend.set_title('region truly constrained?')\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(10, 5)\n",
    "  plt.show()\n",
    "\n",
    "  # Compute the area under the curve for each histogram\n",
    "  for container in ax.containers:\n",
    "    print(container.get_label())\n",
    "    area = 0\n",
    "    for bar in container.patches:\n",
    "      area += bar.get_width() * bar.get_height()\n",
    "    print(f\"Area under the curve: {area:.2f}\")\n",
    "\n",
    "plot_score_distributions(REGIONS, score='min negative_new_chen_score_window', xlabel='Chen score of region', bins=40, xlim=(-6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "def plot_deletion_overlap_distribution(df, regions_class): \n",
    "  k = np.array(df['count SVTYPE']) # number of deletions overlapping each region\n",
    "  poisson_rate_parameter = np.mean(k)\n",
    "\n",
    "  ser = df['count SVTYPE'].value_counts()\n",
    "  number_deletions_overlapping_region = np.array(ser.index) # possible (unique) number of deletions overlapping a region\n",
    "  number_regions = np.array(ser)\n",
    "  total_number_regions = np.sum(number_regions)\n",
    "  probability_deletion_overlaps_region = number_regions / total_number_regions\n",
    "\n",
    "  plt.scatter(number_deletions_overlapping_region, probability_deletion_overlaps_region, label='data')\n",
    "  plt.scatter(number_deletions_overlapping_region, poisson.pmf(number_deletions_overlapping_region, poisson_rate_parameter), label='Poisson fit')\n",
    "  plt.yscale('linear') # 'log'\n",
    "  # plt.ylim([0.0001, 1])\n",
    "  plt.xlim([0, 20])\n",
    "  plt.ylim([0, 0.5])\n",
    "  plt.xlabel('Number of deletions overlapping region')\n",
    "  plt.ylabel('Probability')\n",
    "  plt.legend() \n",
    "  plt.title(\n",
    "    f'{regions_class} regions\\n'\n",
    "    f'{poisson_rate_parameter:.2f} deletions overlap each region on average'\n",
    "  )\n",
    "  plt.show()\n",
    "\n",
    "def plot_deletion_overlap_distribution_wrapper():\n",
    "  constrained = REGIONS['truly constrained']\n",
    "  plot_deletion_overlap_distribution(REGIONS[constrained == True], regions_class='Constrained')\n",
    "  plot_deletion_overlap_distribution(REGIONS[constrained == False], regions_class='Unconstrained')\n",
    "\n",
    "plot_deletion_overlap_distribution_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_constraint_without_deletions(df, zscore_threshold): \n",
    "  score = 'min negative_new_chen_score_window'\n",
    "  df = df[[score, 'truly constrained']].copy()\n",
    "  df['predicted to be constrained'] = df[score] < zscore_threshold\n",
    "  return df\n",
    "\n",
    "predict_constraint_without_deletions(REGIONS, zscore_threshold=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_constraint_using_deletions(df, zscore_threshold): \n",
    "  score = 'min negative_new_chen_score_window'\n",
    "  df = df[[\n",
    "    score, \n",
    "    'truly constrained', \n",
    "    'region is deleted in topmed'\n",
    "  ]].copy()\n",
    "  df['predicted to be constrained'] = (\n",
    "    (df[score] < zscore_threshold) & \n",
    "    (df['region is deleted in topmed'] == False)\n",
    "  )\n",
    "  return df\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "predict_constraint_using_deletions(REGIONS, zscore_threshold=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall(df, zscore_threshold, predict_constraint, log=False): \n",
    "  df = predict_constraint(df, zscore_threshold)\n",
    "  \n",
    "  contingency_table = pd.crosstab(\n",
    "    df['predicted to be constrained'], \n",
    "    df['truly constrained']\n",
    "  )\n",
    "\n",
    "  if log:   \n",
    "    print(zscore_threshold)\n",
    "    print(contingency_table)\n",
    "\n",
    "  tp = contingency_table.loc[True, True]\n",
    "  fp = contingency_table.loc[True, False]\n",
    "  fn = contingency_table.loc[False, True]\n",
    "  precision = tp / (tp + fp)\n",
    "  recall = tp / (tp + fn)\n",
    "\n",
    "  return precision, recall\n",
    "  \n",
    "compute_precision_recall(REGIONS, zscore_threshold=-3, predict_constraint=predict_constraint_without_deletions, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_precision_recall(REGIONS, zscore_threshold=-3, predict_constraint=predict_constraint_using_deletions, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(df, predict_constraint, label): \n",
    "  zscore_thresholds = np.arange(-6, 5.5, 0.1) \n",
    "  precision_recall = [\n",
    "    compute_precision_recall(df, zscore_threshold, predict_constraint, log=False)\n",
    "    for zscore_threshold in zscore_thresholds\n",
    "  ]\n",
    "  precisions, recalls = zip(*precision_recall)\n",
    "  plt.plot(recalls, precisions, label=label)\n",
    "\n",
    "def plot_precision_recall_wrapper(df): \n",
    "  plot_precision_recall(df, predict_constraint_without_deletions, label='without using topmed deletions')\n",
    "  plot_precision_recall(df, predict_constraint_using_deletions, label='using topmed deletions')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.legend()\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(10, 5)\n",
    "\n",
    "  number_unconstrained_regions = df['truly constrained'].value_counts().loc[False]\n",
    "  number_constrained_regions = df['truly constrained'].value_counts().loc[True]\n",
    "  plt.title(\n",
    "    'Predicting constraint on\\n'\n",
    "    f'{number_unconstrained_regions} unconstrained regions\\n'\n",
    "    f'and {number_constrained_regions} constrained regions'\n",
    "  )\n",
    "  \n",
    "plot_precision_recall_wrapper(REGIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constraint-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
