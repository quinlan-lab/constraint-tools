{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TODO (if SNV positions are found to be correlated with variant-effects)] Get attention maps\n",
    "Here is an example on how to retrieve attention maps at a specific layer for a given head and how to plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based upon:\n",
    "# https://github.com/instadeepai/nucleotide-transformer/blob/main/examples/inference.ipynb\n",
    "\n",
    "# I installed nucleotide-transformer using: \n",
    "# pip install git+https://github.com/instadeepai/nucleotide-transformer@main\n",
    "\n",
    "# Another way to use nucleotide-transformer: \n",
    "# https://huggingface.co/InstaDeepAI/nucleotide-transformer-500m-human-ref?text=ACCTGA%3Cmask%3EAACTGAGTC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outs[\"attention_map_layer_1_number_4\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "sns.set_theme(\n",
    "    font_scale=2,\n",
    "    rc={'figure.figsize': (16, 6)}\n",
    ")\n",
    "\n",
    "# plot attention maps\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "seq_length0, seq_length1 = int(sequences_lengths[0]), int(sequences_lengths[1])\n",
    "\n",
    "# plot for first seq in the batch\n",
    "im0 = axes[0].imshow(\n",
    "    outs[\"attention_map_layer_1_number_4\"][\n",
    "        0, 1:(seq_length0 + 1), 1:(seq_length0 + 1)\n",
    "    ]\n",
    ")\n",
    "divider0 = make_axes_locatable(axes[0])\n",
    "cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "tokens0 = tokens_str[0][1 : (seq_length0 + 1)]\n",
    "axes[0].set_xticks(list(range(seq_length0)))\n",
    "axes[0].set_xticklabels(tokens0, rotation=45)\n",
    "axes[0].set_yticks(list(range(seq_length0)))\n",
    "axes[0].set_yticklabels(tokens0, rotation=45)\n",
    "axes[0].grid(False)\n",
    "fig.colorbar(im0, cax=cax0, orientation=\"vertical\")\n",
    "\n",
    "# plot for second seq in the batch\n",
    "im1 = axes[1].imshow(\n",
    "    outs[\"attention_map_layer_1_number_4\"][\n",
    "        1, 1:(seq_length1 + 1), 1:(seq_length1 + 1)\n",
    "    ]\n",
    ")\n",
    "divider1 = make_axes_locatable(axes[1])\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "tokens1 = tokens_str[1][1 : (seq_length1 + 1)]\n",
    "axes[1].set_xticks(list(range(seq_length1)))\n",
    "axes[1].set_xticklabels(tokens1, rotation=45)\n",
    "axes[1].set_yticks(list(range(seq_length1)))\n",
    "axes[1].set_yticklabels(tokens1, rotation=45)\n",
    "axes[1].grid(False)\n",
    "fig.colorbar(im1, cax=cax1, orientation=\"vertical\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constraint-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
